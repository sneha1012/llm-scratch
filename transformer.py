'''LLM is a neural network designed to understand, generate and respond like humans do. deep neural networks models trained on several large text data.
large in large language models refers to both the model parameters size and and also the large datset it is trained on. Parameter \s are wieghts adjusted during training and optimised to predict the next wor in the sequence.

LLMs utilise architecture called Transformers inherently. Which also allows to pay specific attention to the ifferetn parts of the input making it better for human like generation and understanding.
In deep learning, we do not need to choose the best suited features manualy like in machine learning but we do still need labels like - spam or nospam.
LLms are best for mostly automating tasks, be it nay type of unstructured data involving parsing and generating text. LLM from scratch for better fine-tuning or pretuning our other large language models for our domain specifc tasks or datasets.
'''
